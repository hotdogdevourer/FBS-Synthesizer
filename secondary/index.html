<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>FSB4 Formant Speech Synthesizer</title>
<script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>
<style>
* { box-sizing: border-box; margin: 0; padding: 0; }
body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, sans-serif;
    line-height: 1.6;
    color: #333;
    max-width: 900px;
    margin: 2rem auto;
    padding: 1.5rem;
    background: linear-gradient(135deg, #f5f7fa 0%, #e4edf5 100%);
}
h1 {
    text-align: center;
    margin-bottom: 1.5rem;
    color: #2c3e50;
    font-size: 2.2rem;
}
.container {
    background: white;
    border-radius: 16px;
    box-shadow: 0 10px 30px rgba(0,0,0,0.08);
    padding: 2rem;
    margin-top: 1rem;
}
textarea {
    width: 100%;
    height: 160px;
    padding: 1rem;
    border: 2px solid #ddd;
    border-radius: 12px;
    font-size: 1rem;
    margin-bottom: 1.2rem;
    resize: vertical;
    transition: border-color 0.3s;
    font-family: monospace;
}
textarea:focus {
    outline: none;
    border-color: #4a6fa5;
    box-shadow: 0 0 0 3px rgba(74, 111, 165, 0.15);
}
.mode-indicator {
    text-align: center;
    margin-bottom: 1rem;
    padding: 0.6rem;
    border-radius: 10px;
    font-weight: 600;
    transition: all 0.3s ease;
}
.mode-word { background: #e8f5e9; color: #2e7d32; }
.mode-phoneme { background: #e3f2fd; color: #1565c0; }
.mode-spec { background: #f3e5f5; color: #4a148c; }
.mode-unknown { background: #fff8e1; color: #5d4037; }
.controls {
    display: flex;
    gap: 1rem;
    margin-bottom: 1.5rem;
    flex-wrap: wrap;
    align-items: stretch;
}
button {
    flex: 1;
    min-width: 120px;
    padding: 0.9rem 1.5rem;
    background: linear-gradient(to bottom, #4a6fa5, #2c3e50);
    color: white;
    border: none;
    border-radius: 12px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s ease;
    box-shadow: 0 4px 15px rgba(44, 62, 80, 0.3);
}
button:hover:not(:disabled) {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(44, 62, 80, 0.4);
}
button:active:not(:disabled) {
    transform: translateY(0);
}
button:disabled {
    background: #bdc3c7;
    cursor: not-allowed;
    transform: none;
    box-shadow: none;
}
.download-btn {
    background: linear-gradient(to bottom, #27ae60, #219653);
    min-width: 140px;
}
.download-btn:disabled {
    background: #bdc3c7;
    cursor: not-allowed;
    transform: none;
    box-shadow: none;
}
.audio-container {
    margin-top: 1.5rem;
    text-align: center;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 1rem;
}
audio {
    width: 100%;
    max-width: 600px;
    margin-top: 0.5rem;
}
.audio-actions {
    display: flex;
    gap: 1rem;
    margin-top: 0.5rem;
    flex-wrap: wrap;
    justify-content: center;
}
.audio-actions button {
    padding: 0.7rem 1.2rem;
    font-size: 0.95rem;
    min-width: 100px;
}
#status {
    text-align: center;
    margin: 1.2rem 0;
    min-height: 1.8rem;
    font-weight: 500;
    padding: 0.5rem;
    border-radius: 8px;
}
.status-loading { color: #2980b9; background: #e3f2fd; }
.status-ready { color: #27ae60; background: #e8f5e9; }
.status-error { color: #e74c3c; background: #fadbd8; }
.status-processing { color: #8e44ad; background: #f5f9fc; }
.info-box {
    background: #e3f2fd;
    border-left: 4px solid #2980b9;
    padding: 1rem;
    border-radius: 0 8px 8px 0;
    margin: 1.5rem 0;
    font-size: 0.95rem;
}
.phoneme-guide, .spec-guide {
    padding: 1rem;
    border-radius: 0 8px 8px 0;
    margin: 1rem 0;
    font-family: monospace;
    font-size: 0.9rem;
}
.phoneme-guide {
    background: #e8f5e9;
    border-left: 4px solid #2e7d32;
}
.spec-guide {
    background: #f3e5f5;
    border-left: 4px solid #4a148c;
}
.limitations {
    font-size: 0.9rem;
    color: #7f8c8d;
    margin-top: 0.5rem;
    padding-top: 0.5rem;
    border-top: 1px dashed #bdc3c7;
}
.tabs {
    display: flex;
    margin-bottom: 1rem;
    gap: 0.5rem;
    flex-wrap: wrap;
}
.tab {
    padding: 0.6rem 1rem;
    background: #e0e7ff;
    border: none;
    border-radius: 8px 8px 0 0;
    cursor: pointer;
    font-weight: 600;
    flex: 1;
    min-width: 120px;
    text-align: center;
}
.tab.active {
    background: #4a6fa5;
    color: white;
}
.tab-content {
    display: none;
}
.tab-content.active {
    display: block;
}
.example-btn {
    background: linear-gradient(to bottom, #9c27b0, #6a1b9a);
}
@media (max-width: 600px) {
    .controls { flex-direction: column; }
    button { width: 100%; min-width: auto; }
    body { padding: 1rem; margin: 1rem; }
    .tabs { flex-direction: column; }
    .tab { border-radius: 8px; width: 100%; }
    .audio-actions { flex-direction: column; width: 100%; }
}
</style>
</head>
<body>
<h1>ü§ñ FSB4 Formant Speech Synthesizer</h1>
<div class="container">
    <div class="tabs">
        <button class="tab active" data-tab="word">üî§ Word Mode</button>
        <button class="tab" data-tab="phoneme">üëÑ Phoneme Mode</button>
        <button class="tab" data-tab="spec">üéõÔ∏è Spec Mode</button>
    </div>
    
    <div id="word-tab" class="tab-content active">
        <textarea id="textInput" placeholder="Enter words (e.g., 'hello world robot')">hello world this is a robot voice</textarea>
        <div id="modeIndicator" class="mode-indicator mode-unknown">‚ùì Input mode will auto-detect</div>
    </div>
    
    <div id="phoneme-tab" class="tab-content">
        <textarea id="phonemeInput" placeholder="Enter phonemes separated by spaces (e.g., HH EH L OW SIL W ER L D)">HH EH L OW SIL W ER L D</textarea>
        <div class="phoneme-guide">
            <strong>Valid Phonemes (ARPABET):</strong><br>
            SIL, AH, AE, AA, AO, EH, EY, IH, IY, OW, UH, UW, ER,<br>
            B, D, G, P, T, K, M, N, NG, L, R, F, S, SH, TH, DH, V, Z, ZH, W, Y, HH, CH, JH<br>
            <strong>Tip:</strong> Use SIL between words for natural pauses
        </div>
    </div>
    
    <div id="spec-tab" class="tab-content">
        <textarea id="specInput" placeholder="Enter spec format: PHON DUR RISE FALL"># Hello World with pitch variation
HH       0.150  0.010  120.0
EH       0.140  0.018  115.0
L        0.120  0.008  115.0
OW       0.180  0.018  115.0 105.0
SIL      0.120  0.008  0.0
W        0.120  0.008  110.0
ER       0.140  0.018  115.0
L        0.120  0.008  115.0
D        0.068  0.008  0.0</textarea>
        <div class="spec-guide">
            <strong>Spec Format:</strong> PHON DURATION RISE [FALL]<br>
            Example: <code>OW 0.180 0.018 115.0 105.0</code><br>
            ‚Ä¢ DURATION in seconds<br>
            ‚Ä¢ RISE = starting pitch (Hz)<br>
            ‚Ä¢ FALL (optional) = ending pitch (Hz)
        </div>
    </div>
    
    <div class="controls">
        <button id="synthesizeBtn" disabled>‚ñ∂Ô∏è Synthesize</button>
        <button id="playExampleBtn" disabled class="example-btn">üéµ Example</button>
        <button id="downloadBtn" disabled class="download-btn">üíæ Download WAV</button>
    </div>
    
    <div id="status" class="status-loading">Initializing Pyodide environment...</div>
    
    <div class="info-box">
        <strong>‚ÑπÔ∏è About FSB4:</strong> Formant-based speech synthesizer running entirely in-browser via Pyodide.<br>
        Converts text ‚Üí phonemes ‚Üí formant synthesis ‚Üí WAV audio. No server required!
    </div>
    
    <div class="audio-container">
        <audio id="audioPlayer" controls>Your browser does not support the audio element.</audio>
        <div class="audio-actions">
            <button id="playBtn" disabled>‚ñ∂Ô∏è Play</button>
            <button id="pauseBtn" disabled>‚è∏Ô∏è Pause</button>
        </div>
    </div>
    
    <div class="limitations">
        ‚ö†Ô∏è <strong>Limitations:</strong> GitHub Pages has no server-side processing. All synthesis happens in your browser via WebAssembly (Pyodide). First load may take 15-30 seconds to initialize Python environment.
    </div>
</div>

<script type="text/python" id="fsb4-source">
import numpy as np
import scipy.signal as sig
import wave
import re
import json
from typing import Dict, List, Tuple, Optional
from io import BytesIO

# ======================
# FSB4 CORE ENGINE
# ======================

smp = 97000  # Sample rate

# Formant definitions (F1, F2, F3, F4) in Hz + bandwidths
VOWEL_FORMANTS = {
    'AH': ([750, 1300, 2400, 3800], [80, 100, 200, 300]),
    'AE': ([750, 1400, 2400, 3800], [80, 100, 200, 300]),
    'AA': ([750, 1100, 2400, 3800], [80, 100, 200, 300]),
    'AO': ([600, 900, 2400, 3800], [80, 100, 200, 300]),
    'EH': ([600, 1700, 2400, 3800], [80, 100, 200, 300]),
    'EY': ([400, 2100, 2800, 3800], [60, 90, 180, 280]),
    'IH': ([400, 1800, 2600, 3800], [60, 90, 180, 280]),
    'IY': ([300, 2300, 3000, 3800], [60, 90, 180, 280]),
    'OW': ([400, 900, 2400, 3800], [60, 90, 180, 280]),
    'UH': ([400, 1000, 2200, 3800], [60, 90, 180, 280]),
    'UW': ([300, 800, 2200, 3800], [60, 90, 180, 280]),
    'ER': ([500, 1500, 2000, 3800], [70, 100, 180, 280]),
}

# Consonant definitions (duration in seconds)
CONSONANT_DURATIONS = {
    'SIL': 0.08,
    'B': 0.05, 'D': 0.05, 'G': 0.06,
    'P': 0.06, 'T': 0.06, 'K': 0.07,
    'M': 0.10, 'N': 0.10, 'NG': 0.12,
    'L': 0.10, 'R': 0.12,
    'F': 0.10, 'S': 0.12, 'SH': 0.12, 'TH': 0.10,
    'DH': 0.10, 'V': 0.10, 'Z': 0.12, 'ZH': 0.12,
    'W': 0.10, 'Y': 0.08, 'HH': 0.10,
    'CH': 0.08, 'JH': 0.08,
}

# Text-to-phoneme mapping (simplified)
WORD_TO_PHONEMES = {
    'HELLO': ['HH', 'EH', 'L', 'OW'],
    'WORLD': ['W', 'ER', 'L', 'D'],
    'THIS': ['DH', 'IH', 'S'],
    'IS': ['IH', 'Z'],
    'A': ['AH'],
    'ROBOT': ['R', 'OW', 'B', 'AA', 'T'],
    'VOICE': ['V', 'AO', 'Y', 'S'],
    'TEST': ['T', 'EH', 'S', 'T'],
    'SPEECH': ['S', 'P', 'IY', 'CH'],
    'SYNTHESIS': ['S', 'IH', 'N', 'TH', 'AH', 'S', 'IH', 'S'],
}

class VoiceParameters:
    def __init__(self):
        self.pitch_base = 110.0
        self.pitch_range = 20.0
        self.formant_shift = 1.0
        self.vowel_duration = 0.14
        self.consonant_duration = 0.08
        self.attack_time = 0.01
        self.release_time = 0.02
        self.breathiness = 0.03

class VoiceRegistry:
    def __init__(self):
        self.current_voice = VoiceParameters()
    
    def set_voice(self, params: VoiceParameters):
        self.current_voice = params

VOICE_REGISTRY = VoiceRegistry()

class FormantFilter:
    def __init__(self, freq: float, bw: float, sr: int):
        w0 = 2 * np.pi * freq / sr
        bw_rad = 2 * np.pi * bw / sr
        self.a1 = -2 * np.cos(w0)
        self.a2 = np.exp(-bw_rad)
        self.b0 = (1 - self.a2) * np.sqrt(1 + self.a2)
        self.x1 = self.x2 = 0.0
        self.y1 = self.y2 = 0.0
    
    def process(self, x: float) -> float:
        y = self.b0 * x - self.a1 * self.y1 - self.a2 * self.y2
        self.x2, self.x1 = self.x1, x
        self.y2, self.y1 = self.y1, y
        return y

class FormantSynthesizer:
    def __init__(self, voice: VoiceParameters):
        self.voice = voice
        self.sr = smp
    
    def generate_excitation(self, duration: float, pitch: float) -> np.ndarray:
        n_samples = int(duration * self.sr)
        excitation = np.zeros(n_samples)
        
        if pitch > 0:
            period = int(self.sr / pitch)
            for i in range(0, n_samples, period):
                if i < n_samples:
                    excitation[i] = 1.0
            # Add breathiness (noise)
            noise = np.random.randn(n_samples) * self.voice.breathiness
            excitation = excitation + noise
        else:
            # Unvoiced = noise only
            excitation = np.random.randn(n_samples) * 0.8
        
        return excitation
    
    def apply_formants(self, signal: np.ndarray, formants: List[float], bandwidths: List[float]) -> np.ndarray:
        output = signal.copy()
        for freq, bw in zip(formants, bandwidths):
            if freq > 0:
                filt = FormantFilter(freq * self.voice.formant_shift, bw, self.sr)
                output = np.array([filt.process(s) for s in output])
        return output
    
    def apply_envelope(self, signal: np.ndarray, attack: float, release: float) -> np.ndarray:
        n = len(signal)
        attack_samples = int(attack * self.sr)
        release_samples = int(release * self.sr)
        
        env = np.ones(n)
        if attack_samples > 0:
            env[:attack_samples] = np.linspace(0, 1, attack_samples)
        if release_samples > 0 and n > release_samples:
            env[-release_samples:] = np.linspace(1, 0, release_samples)
        
        return signal * env
    
    def synthesize_phoneme(self, phoneme: str, duration: float, pitch_start: float, pitch_end: Optional[float] = None) -> np.ndarray:
        if phoneme in VOWEL_FORMANTS:
            formants, bandwidths = VOWEL_FORMANTS[phoneme]
            pitch = pitch_end if pitch_end is not None else pitch_start
            excitation = self.generate_excitation(duration, pitch)
            filtered = self.apply_formants(excitation, formants, bandwidths)
            enveloped = self.apply_envelope(filtered, self.voice.attack_time, self.voice.release_time)
            return enveloped
        else:
            # Consonant = mostly silence with noise burst
            n_samples = int(duration * self.sr)
            return np.random.randn(n_samples) * 0.1 * (0.5 if phoneme in ['S', 'SH', 'F', 'TH'] else 0.2)
    
    def synthesize_from_specs(self, specs: List[Tuple[str, float, float, Optional[float]]]) -> np.ndarray:
        chunks = []
        for phoneme, duration, pitch_start, pitch_end in specs:
            chunk = self.synthesize_phoneme(phoneme, duration, pitch_start, pitch_end)
            chunks.append(chunk)
        
        if not chunks:
            return np.zeros(int(0.5 * self.sr))
        
        return np.concatenate(chunks)

def text_to_phonemes(text: str) -> List[str]:
    words = re.findall(r'\b\w+\b', text.lower())
    phonemes = []
    for i, word in enumerate(words):
        if i > 0:
            phonemes.append('SIL')
        phonemes.extend(WORD_TO_PHONEMES.get(word.upper(), ['AH']))
    return phonemes

def phonemes_to_spec(phonemes: List[str], voice: VoiceParameters) -> List[Tuple[str, float, float, Optional[float]]]:
    specs = []
    for i, ph in enumerate(phonemes):
        duration = voice.vowel_duration if ph in VOWEL_FORMANTS else CONSONANT_DURATIONS.get(ph, 0.08)
        pitch = voice.pitch_base + (voice.pitch_range * 0.5 * np.sin(i * 0.3))
        specs.append((ph, duration, pitch, None))
    return specs

def is_spec_format(text: str) -> bool:
    lines = [l.strip() for l in text.strip().split('\n') if l.strip() and not l.strip().startswith('#')]
    if not lines:
        return False
    for line in lines[:3]:
        parts = line.split()
        if len(parts) < 3:
            return False
        if not parts[0].isalpha():
            return False
        try:
            float(parts[1])
            float(parts[2])
        except:
            return False
    return True

def parse_phoneme_spec(text: str, voice: VoiceParameters) -> List[Tuple[str, float, float, Optional[float]]]:
    specs = []
    lines = [l.strip() for l in text.strip().split('\n') if l.strip() and not l.strip().startswith('#')]
    for line in lines:
        parts = line.split()
        if len(parts) < 3:
            continue
        phoneme = parts[0].upper()
        duration = float(parts[1])
        pitch_start = float(parts[2])
        pitch_end = float(parts[3]) if len(parts) > 3 else None
        specs.append((phoneme, duration, pitch_start, pitch_end))
    return specs

def parse_phoneme_input(text: str) -> List[str]:
    tokens = re.findall(r'[A-Z]+', text.upper())
    valid_tokens = [t for t in tokens if t in VOWEL_FORMANTS or t in CONSONANT_DURATIONS]
    return valid_tokens

def generate_wav_bytes(audio: np.ndarray, sr: int = smp) -> bytes:
    """Generate WAV bytes with proper header and clipping"""
    try:
        # Ensure audio is in correct range [-1.0, 1.0]
        audio_normalized = np.clip(audio, -1.0, 1.0)
        
        # Convert to 16-bit PCM
        audio_int16 = (audio_normalized * 32767).astype(np.int16)
        
        # Create WAV in memory with proper structure
        buffer = BytesIO()
        
        with wave.open(buffer, 'wb') as wf:
            wf.setnchannels(1)           # Mono
            wf.setsampwidth(2)           # 16-bit
            wf.setframerate(sr)          # Sample rate
            wf.writeframes(audio_int16.tobytes())
        
        wav_bytes = buffer.getvalue()
        buffer.close()
        
        # Validate WAV header (first 44 bytes should be valid)
        if len(wav_bytes) < 44:
            raise ValueError(f"WAV too short: {len(wav_bytes)} bytes")
        
        # Check RIFF header
        if wav_bytes[:4] != b'RIFF':
            raise ValueError("Invalid WAV header: missing RIFF marker")
        
        return wav_bytes
        
    except Exception as e:
        print(f"WAV generation error: {e}")
        import traceback
        traceback.print_exc()
        # Fallback: generate 0.5s of silence
        fallback = np.zeros(int(0.5 * sr))
        return generate_wav_bytes(fallback, sr)

def synthesize_text(text: str):
    try:
        text = text.strip()
        if not text:
            return generate_wav_bytes(np.zeros(int(0.5 * smp))), "empty"
        
        # Detect mode
        if is_spec_format(text):
            specs = parse_phoneme_spec(text, VOICE_REGISTRY.current_voice)
            mode = "spec"
        else:
            tokens = text.upper().split()
            valid_phonemes = set(list(VOWEL_FORMANTS.keys()) + list(CONSONANT_DURATIONS.keys()))
            if tokens and all(t in valid_phonemes for t in tokens):
                phonemes = parse_phoneme_input(text)
                specs = phonemes_to_spec(phonemes, VOICE_REGISTRY.current_voice)
                mode = "phoneme"
            else:
                phonemes = text_to_phonemes(text)
                specs = phonemes_to_spec(phonemes, VOICE_REGISTRY.current_voice)
                mode = "word"
        
        # Synthesize
        synth = FormantSynthesizer(VOICE_REGISTRY.current_voice)
        audio = synth.synthesize_from_specs(specs)
        
        # Final safety clip
        audio = np.clip(audio, -1.0, 1.0)
        
        return generate_wav_bytes(audio), mode
        
    except Exception as e:
        print(f"Synthesis error: {e}")
        import traceback
        traceback.print_exc()
        # Return silence on error
        return generate_wav_bytes(np.zeros(int(0.5 * smp))), "error"
</script>

<script>
// ======================
// JAVASCRIPT FRONTEND
// ======================

let pyodide;
let synthesizeFunc;
let currentAudioUrl = null;
let currentWavBlob = null;

const statusEl = document.getElementById('status');
const synthesizeBtn = document.getElementById('synthesizeBtn');
const playExampleBtn = document.getElementById('playExampleBtn');
const downloadBtn = document.getElementById('downloadBtn');
const playBtn = document.getElementById('playBtn');
const pauseBtn = document.getElementById('pauseBtn');
const audioPlayer = document.getElementById('audioPlayer');
const textInput = document.getElementById('textInput');
const phonemeInput = document.getElementById('phonemeInput');
const specInput = document.getElementById('specInput');
const modeIndicator = document.getElementById('modeIndicator');

// Tab switching
document.querySelectorAll('.tab').forEach(tab => {
    tab.addEventListener('click', () => {
        document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
        tab.classList.add('active');
        document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
        const tabName = tab.dataset.tab;
        document.getElementById(`${tabName}-tab`).classList.add('active');
        
        // Update mode indicator based on tab
        if (tabName === 'word') {
            modeIndicator.className = 'mode-indicator mode-word';
            modeIndicator.textContent = 'üî§ Word Mode';
        } else if (tabName === 'phoneme') {
            modeIndicator.className = 'mode-indicator mode-phoneme';
            modeIndicator.textContent = 'üëÑ Phoneme Mode';
        } else {
            modeIndicator.className = 'mode-indicator mode-spec';
            modeIndicator.textContent = 'üéõÔ∏è Spec Mode';
        }
    });
});

// Real-time mode detection for word tab
textInput.addEventListener('input', () => {
    const text = textInput.value.trim();
    if (!text) {
        modeIndicator.className = 'mode-indicator mode-unknown';
        modeIndicator.textContent = '‚ùì Input mode will auto-detect';
        return;
    }
    const tokens = text.toUpperCase().split(/\s+/);
    const validPhonemes = new Set([
        'SIL', 'AH', 'AE', 'AA', 'AO', 'EH', 'EY', 'IH', 'IY', 'OW', 'UH', 'UW', 'ER',
        'B', 'D', 'G', 'P', 'T', 'K', 'M', 'N', 'NG', 'L', 'R', 'F', 'S', 'SH', 'TH',
        'DH', 'V', 'Z', 'ZH', 'W', 'Y', 'HH', 'CH', 'JH'
    ]);
    if (tokens.every(t => validPhonemes.has(t))) {
        modeIndicator.className = 'mode-indicator mode-phoneme';
        modeIndicator.textContent = 'üëÑ Phoneme Mode Detected';
    } else {
        modeIndicator.className = 'mode-indicator mode-word';
        modeIndicator.textContent = 'üî§ Word Mode';
    }
});

async function setupPyodide() {
    updateStatus("Loading Pyodide...", "status-loading");
    try {
        pyodide = await loadPyodide({
            indexURL: "https://cdn.jsdelivr.net/pyodide/v0.24.1/full/"
        });
        
        updateStatus("Installing packages...", "status-loading");
        await pyodide.loadPackage(["numpy", "scipy"]);
        
        const fsb4Source = document.getElementById('fsb4-source').textContent;
        updateStatus("Initializing speech engine...", "status-loading");
        
        pyodide.runPython(fsb4Source);
        
        pyodide.runPython(`
def js_synthesize(text):
    try:
        wav_bytes, mode = synthesize_text(text)
        return wav_bytes, mode
    except Exception as e:
        import traceback
        print("Python error:")
        traceback.print_exc()
        return None, "error"
`);
        
        synthesizeFunc = pyodide.globals.get("js_synthesize");
        
        updateStatus("‚úÖ Ready! Enter text and click Synthesize", "status-ready");
        synthesizeBtn.disabled = false;
        playExampleBtn.disabled = false;
        
    } catch (error) {
        console.error("Pyodide setup failed:", error);
        updateStatus(`‚ùå Initialization failed: ${error.message}`, "status-error");
    }
}

function updateStatus(message, className) {
    statusEl.textContent = message;
    statusEl.className = className;
}

async function synthesize(text) {
    if (!synthesizeFunc) {
        alert("Engine not ready yet. Please wait.");
        return null;
    }
    
    try {
        updateStatus("üîä Synthesizing...", "status-processing");
        synthesizeBtn.disabled = true;
        playExampleBtn.disabled = true;
        downloadBtn.disabled = true;
        playBtn.disabled = true;
        pauseBtn.disabled = true;
        
        // Call Python synthesis
        const result = synthesizeFunc(text);
        if (!result || result[0] === null) {
            throw new Error("Synthesis returned null");
        }
        
        const [wavBytes, mode] = result;
        
        // Convert to JavaScript Uint8Array
        const wavArray = wavBytes.toJs();
        wavBytes.destroy();
        
        if (!wavArray || wavArray.length < 44) {
            throw new Error(`Invalid WAV data: ${wavArray ? wavArray.length : 0} bytes`);
        }
        
        // Create Blob from Uint8Array
        const wavBuffer = wavArray.buffer.slice(wavArray.byteOffset, wavArray.byteOffset + wavArray.byteLength);
        currentWavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
        
        // Create URL for audio element
        if (currentAudioUrl) {
            URL.revokeObjectURL(currentAudioUrl);
        }
        currentAudioUrl = URL.createObjectURL(currentWavBlob);
        
        // Set audio source
        audioPlayer.src = currentAudioUrl;
        audioPlayer.load();
        
        // Enable controls after audio is ready
        audioPlayer.onloadeddata = () => {
            downloadBtn.disabled = false;
            playBtn.disabled = false;
            pauseBtn.disabled = false;
            
            const modeNames = {
                'word': 'Text',
                'phoneme': 'Phonemes', 
                'spec': 'Spec',
                'empty': 'Empty',
                'error': 'Error'
            };
            
            const sizeKB = (wavArray.length / 1024).toFixed(1);
            updateStatus(`‚úÖ ${modeNames[mode] || mode} synthesized! (${sizeKB} KB)`, "status-ready");
        };
        
        audioPlayer.onerror = (e) => {
            console.error("Audio load error:", e);
            updateStatus(`‚ùå Audio playback failed. Try downloading instead.`, "status-error");
            downloadBtn.disabled = false;
        };
        
        return currentAudioUrl;
        
    } catch (error) {
        console.error("Synthesis error:", error);
        updateStatus(`‚ùå Synthesis failed: ${error.message}`, "status-error");
        alert(`Synthesis failed: ${error.message}\n\nCheck console for details.`);
        return null;
    } finally {
        synthesizeBtn.disabled = false;
        playExampleBtn.disabled = false;
    }
}

function downloadWav() {
    if (!currentWavBlob) {
        alert("No audio to download. Please synthesize first.");
        return;
    }
    
    try {
        // Get filename based on current tab
        const activeTab = document.querySelector('.tab.active').dataset.tab;
        let filename = 'fsb4_output';
        
        if (activeTab === 'word') {
            const text = textInput.value.trim().substring(0, 30).replace(/[^\w\s]/g, '');
            filename = text ? `fsb4_${text.replace(/\s+/g, '_')}` : 'fsb4_output';
        } else if (activeTab === 'phoneme') {
            filename = 'fsb4_phonemes';
        } else {
            filename = 'fsb4_spec';
        }
        
        // Create download link
        const downloadUrl = URL.createObjectURL(currentWavBlob);
        
        const link = document.createElement('a');
        link.href = downloadUrl;
        link.download = `${filename}.wav`;
        
        // Append to body, click, then remove
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
        
        // Clean up URL after download
        setTimeout(() => URL.revokeObjectURL(downloadUrl), 1000);
        
        updateStatus("üíæ Download started!", "status-ready");
        
    } catch (error) {
        console.error("Download error:", error);
        alert(`Download failed: ${error.message}`);
    }
}

// Playback controls
playBtn.addEventListener('click', () => {
    if (audioPlayer.src) {
        audioPlayer.play().catch(e => {
            console.log("Autoplay prevented:", e);
            alert("Browser blocked autoplay. Click directly on the audio player controls to play.");
        });
    }
});

pauseBtn.addEventListener('click', () => {
    audioPlayer.pause();
});

// Synthesize button
synthesizeBtn.addEventListener('click', async () => {
    const activeTab = document.querySelector('.tab.active').dataset.tab;
    let text;
    
    if (activeTab === 'word') {
        text = textInput.value.trim();
    } else if (activeTab === 'phoneme') {
        text = phonemeInput.value.trim();
    } else {
        text = specInput.value.trim();
    }
    
    if (!text) {
        alert("Please enter some input first!");
        return;
    }
    
    await synthesize(text);
});

// Example button
playExampleBtn.addEventListener('click', async () => {
    const activeTab = document.querySelector('.tab.active').dataset.tab;
    
    if (activeTab === 'word') {
        textInput.value = "hello world this is a robot voice";
        await synthesize(textInput.value);
    } else if (activeTab === 'phoneme') {
        phonemeInput.value = "HH EH L OW SIL W ER L D SIL DH IH S SIL IH Z SIL AH SIL R OW B AA T SIL V AO Y S";
        await synthesize(phonemeInput.value);
    } else {
        specInput.value = `# Hello World with pitch variation
HH       0.150  0.010  120.0
EH       0.140  0.018  115.0
L        0.120  0.008  115.0
OW       0.180  0.018  115.0 105.0
SIL      0.120  0.008  0.0
W        0.120  0.008  110.0
ER       0.140  0.018  115.0
L        0.120  0.008  115.0
D        0.068  0.008  0.0`;
        await synthesize(specInput.value);
    }
});

// Download button
downloadBtn.addEventListener('click', downloadWav);

// Cleanup on page unload
window.addEventListener('beforeunload', () => {
    if (currentAudioUrl) {
        URL.revokeObjectURL(currentAudioUrl);
    }
});

// Initialize
window.addEventListener('load', setupPyodide);
</script>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FSB4 Speech Synthesizer (Pyodide)</title>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.25.0/full/pyodide.js"></script>
    <style>
        body { font-family: system-ui, -apple-system, sans-serif; max-width: 800px; margin: 20px auto; padding: 20px; background: #f1f5f9; color: #1e293b; }
        .container { background: white; border-radius: 16px; padding: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.08); }
        h1 { text-align: center; color: #4338ca; margin-bottom: 8px; font-size: 28px; }
        .subtitle { text-align: center; color: #64748b; margin-bottom: 25px; font-size: 16px; }
        .status { background: #0f172a; color: #38bdf8; padding: 16px; border-radius: 10px; font-family: monospace; margin: 20px 0; min-height: 26px; line-height: 1.5; }
        textarea { width: 100%; height: 180px; padding: 16px; border: 2px solid #cbd5e1; border-radius: 12px; font-family: monospace; font-size: 16px; resize: vertical; margin: 15px 0; background: #f8fafc; }
        .controls { display: flex; flex-wrap: wrap; gap: 15px; margin: 25px 0; justify-content: center; }
        button { background: linear-gradient(to right, #4338ca, #5b21b6); color: white; border: none; padding: 14px 28px; border-radius: 12px; font-weight: 600; cursor: pointer; transition: all 0.25s; font-size: 17px; box-shadow: 0 4px 10px rgba(67, 56, 202, 0.25); }
        button:hover { transform: translateY(-2px); box-shadow: 0 6px 15px rgba(67, 56, 202, 0.35); }
        button:disabled { background: #94a3b8; cursor: not-allowed; transform: none; opacity: 0.85; box-shadow: none; }
        button.stop { background: linear-gradient(to right, #dc2626, #b91c1c); }
        .loading { text-align: center; padding: 50px 20px; }
        .spinner { border: 5px solid #cbd5e1; border-top: 5px solid #4338ca; border-radius: 50%; width: 50px; height: 50px; animation: spin 1s linear infinite; margin: 0 auto 25px; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        #loading-status { font-size: 20px; color: #4338ca; font-weight: 600; margin-top: 15px; }
        .error { background: #fef2f2; color: #b91c1c; padding: 18px; border-radius: 12px; margin: 20px 0; border-left: 4px solid #ef4444; font-weight: 500; }
    </style>
</head>
<body>
    <div class="container">
        <h1>FSB4 Speech Synthesizer</h1>
        <div class="subtitle">Formant synthesis with crossfade blending ‚Ä¢ Runs entirely in-browser</div>
        
        <div id="loading-screen" class="loading">
            <div class="spinner"></div>
            <div id="loading-status">Initializing Pyodide...</div>
            <div style="color: #64748b; font-size: 15px; margin-top: 12px;">(First load: 20-45 seconds ‚Ä¢ Cached thereafter)</div>
        </div>
        
        <div id="main-app" style="display:none;">
            <div class="status" id="status-bar">Ready ‚Ä¢ Enter phonemes below ‚Üí Click "Render"</div>
            
            <label style="font-weight: 600; display: block; margin-bottom: 10px; font-size: 17px;">Phoneme Spec (PHONEME DUR OVRLP P0):</label>
            <textarea id="spec-editor" spellcheck="false">SIL  0.190 0.000 0.0
HH   0.080 0.012 115.0
EH   0.120 0.025 115.0
L    0.110 0.015 115.0
OW   0.180 0.000 105.0
SIL  0.280 0.000 0.0</textarea>
            
            <div class="controls">
                <button id="render-btn" onclick="renderAudio()">üé® Render Audio</button>
                <button id="play-btn" onclick="togglePlayback()" disabled>‚ñ∂ Play</button>
                <button id="export-btn" onclick="exportWAV()" disabled>üíæ Export WAV</button>
            </div>
            
            <div id="error-container"></div>
        </div>
    </div>

    <script>
        let pyodide = null;
        let renderedAudio = null;
        let audioContext = null;
        let audioBuffer = null;
        let isPlaying = false;
        let sourceNode = null;
        const SAMPLE_RATE = 48000;
        
        // Initialize Pyodide and define Python functions
        async function initPyodide() {
            try {
                document.getElementById('loading-status').textContent = "Loading Pyodide runtime...";
                pyodide = await loadPyodide();
                
                document.getElementById('loading-status').textContent = "Installing numpy...";
                await pyodide.loadPackage("numpy");
                
                document.getElementById('loading-status').textContent = "Installing scipy...";
                await pyodide.loadPackage("scipy");
                
                document.getElementById('loading-status').textContent = "Loading FSB4 engine...";
                
                // Define Python functions that will be callable from JS
                await pyodide.runPythonAsync(`
import numpy as np
import scipy.signal as sig

# Minimal FSB4 phoneme set
VOWELS = {'AH','AE','AA','AO','EH','EY','IH','IY','OW','UH','UW','ER'}
STOPS = {'P','T','K','B','D','G','CH'}
BYTE_TO_PHONEME = {i: v for i, v in enumerate([
    'SIL','AH','AE','AA','AO','EH','EY','IH','IY','OW','UH','UW','ER','B',
    'D','G','P','T','K','M','N','NG','L','R','F','S','SH','TH','DH','V','Z','ZH','W','Y','HH','CH','JH'
])}

# Minimal voice data
VOICE_DATA = {
    'AH': {'f1': 700, 'f2': 1100, 'f3': 2400, 'length': 0.14},
    'EH': {'f1': 530, 'f2': 1700, 'f3': 2450, 'length': 0.14},
    'IH': {'f1': 420, 'f2': 1950, 'f3': 2500, 'length': 0.14},
    'OW': {'f1': 450, 'f2': 900, 'f3': 2350, 'length': 0.14},
    'L':  {'f1': 400, 'f2': 1150, 'f3': 2450, 'length': 0.12},
    'HH': {'f1': None, 'f2': None, 'f3': None, 'length': 0.125},
    'M':  {'f1': 350, 'f2': 1050, 'f3': 2250, 'length': 0.12},
    'N':  {'f1': 320, 'f2': 1150, 'f3': 2450, 'length': 0.12},
    'NG': {'f1': 280, 'f2': 950, 'f3': 2350, 'length': 0.12},
    'R':  {'f1': 450, 'f2': 1250, 'f3': 1500, 'length': 0.12},
    'SIL':{'f1': 0, 'f2': 0, 'f3': 0, 'length': 0.19},
}

def get_phoneme_data(ph):
    return VOICE_DATA.get(ph, VOICE_DATA['SIL'])

def parse_spec(text):
    specs = []
    for line in text.strip().splitlines():
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        parts = line.split()
        if len(parts) < 4:
            continue
        ph = parts[0].upper()
        if ph not in VOICE_DATA:
            continue
        try:
            dur = max(0.01, min(2.0, float(parts[1])))
            overlap = max(0.0, min(0.5, float(parts[2])))
            pitch = [float(parts[3])]
            ph_data = get_phoneme_data(ph)
            specs.append({
                'phoneme': ph,
                'duration': dur,
                'overlap': overlap,
                'pitch_contour': pitch,
                'f1': ph_data.get('f1', 0) or 0,
                'f2': ph_data.get('f2', 0) or 0,
                'f3': ph_data.get('f3', 0) or 0,
                'voiced': ph not in {'SIL','B','D','G','P','T','K','F','S','SH','TH','HH','CH'}
            })
        except:
            continue
    return specs

def stable_resonator(fs, freq, bw):
    if freq <= 0:
        return np.array([1.0]), np.array([1.0])
    w0 = 2 * np.pi * freq / fs
    bw_rad = max(2 * np.pi * bw / fs, 2 * np.pi * 80 / fs)
    a1 = -2 * np.exp(-bw_rad/2) * np.cos(w0)
    a2 = np.exp(-bw_rad)
    b0 = np.sqrt(1 - a2)
    return np.array([b0]), np.array([1.0, a1, a2])

def apply_formants(fs, signal, f1, f2, f3):
    for freq, bw in [(f1, 60), (f2, 90), (f3, 150)]:
        if freq and freq > 50:
            b, a = stable_resonator(fs, freq, bw)
            signal = sig.lfilter(b, a, signal)
    b, a = sig.butter(1, 900/(fs/2), btype='high')
    return sig.lfilter(b, a, signal)

def synthesize_phoneme(fs, spec):
    ph = spec['phoneme']
    dur = spec['duration']
    f1, f2, f3 = spec['f1'], spec['f2'], spec['f3']
    pitch = spec['pitch_contour'][0] if spec['pitch_contour'] else 115.0
    voiced = spec['voiced']
    
    n = int(dur * fs)
    if ph == 'SIL':
        return np.zeros(n)
    
    if not voiced and ph not in VOWELS:
        noise = np.random.randn(n)
        b, a = sig.butter(4, 7500/(fs/2), btype='low')
        noise = sig.filtfilt(b, a, noise)
        if f1 > 50:
            noise = apply_formants(fs, noise, f1, f2, f3)
        out = noise * 0.35
    else:
        t = np.arange(n) / fs
        glottal = np.sin(2 * np.pi * pitch * t)
        if f1 > 50:
            out = apply_formants(fs, glottal, f1, f2, f3)
        else:
            out = glottal * 0.5
    
    # Simple envelope
    env = np.ones(n)
    att = min(0.008, dur * 0.15)
    rel = min(0.02, dur * 0.3)
    att_s = int(att * fs)
    rel_s = int(rel * fs)
    if att_s > 0:
        env[:att_s] = np.linspace(0, 1, att_s)
    if rel_s > 0:
        env[-rel_s:] = np.linspace(1, 0.1, rel_s)
    out = out * env * 0.85
    return np.tanh(out * 1.2) * 0.9

def synthesize(specs):
    fs = 48000
    if not specs:
        return np.zeros(0)
    
    # Calculate total duration with overlaps
    total_dur = sum(s['duration'] for s in specs)
    for i in range(len(specs) - 1):
        total_dur -= min(specs[i].get('overlap', 0.0), specs[i]['duration'])
    
    total_samples = int(total_dur * fs) + 20
    output = np.zeros(total_samples)
    pos = 0
    
    for i, spec in enumerate(specs):
        audio = synthesize_phoneme(fs, spec)
        samples = len(audio)
        
        # Determine overlap with next phoneme
        overlap = spec.get('overlap', 0.0) if i < len(specs) - 1 else 0.0
        overlap_samples = min(int(overlap * fs), samples - 1, int(spec['duration'] * fs * 0.5))
        
        # Mix into output buffer (simple additive blending)
        end = pos + samples
        if end > len(output):
            output = np.resize(output, end + 1000)
        
        output[pos:end] += audio
        pos += (samples - overlap_samples)
    
    # Final processing
    actual_len = min(pos, len(output))
    audio = output[:actual_len]
    audio = np.tanh(audio * 1.3) * 0.92
    b, a = sig.butter(5, 5000/(fs/2), btype='low')
    audio = sig.filtfilt(b, a, audio)
    return audio
                `);
                
                // Hide loader, show app
                document.getElementById('loading-screen').style.display = 'none';
                document.getElementById('main-app').style.display = 'block';
                updateStatus("‚úì Ready ‚Ä¢ Enter phonemes and click 'Render Audio'");
                
            } catch (error) {
                console.error("Initialization failed:", error);
                document.getElementById('loading-status').textContent = "‚ùå FAILED TO LOAD";
                document.getElementById('loading-status').style.color = '#dc2626';
                document.querySelector('.spinner').style.borderColor = '#fecaca';
                document.querySelector('.spinner').style.borderTopColor = '#dc2626';
                showError(`Initialization error: ${error.message || error.toString()}`);
            }
        }
        
        function updateStatus(msg) {
            document.getElementById('status-bar').textContent = msg;
        }
        
        function showError(msg) {
            const container = document.getElementById('error-container');
            container.innerHTML = `<div class="error">${msg}</div>`;
            setTimeout(() => { container.innerHTML = ''; }, 12000);
        }
        
        async function renderAudio() {
            if (!pyodide) {
                showError("Engine still loading. Please wait...");
                return;
            }
            
            const text = document.getElementById('spec-editor').value.trim();
            if (!text) {
                showError("Please enter phoneme spec text first!");
                return;
            }
            
            try {
                const btn = document.getElementById('render-btn');
                btn.disabled = true;
                btn.textContent = '.Rendering...';
                updateStatus("Parsing phoneme spec...");
                
                // CRITICAL: Get callable function reference EACH TIME before calling
                const parseFunc = pyodide.globals.get('parse_spec');
                const specsProxy = parseFunc(text);  // Call immediately
                parseFunc.destroy();  // Clean up PyProxy
                
                const specs = specsProxy.toJs({ depth: -1 });
                specsProxy.destroy();
                
                if (!specs || specs.length < 2) {
                    throw new Error("No valid phonemes parsed. Format: PHONEME DUR OVRLP P0");
                }
                
                updateStatus(`Synthesizing ${specs.length} phonemes with crossfade...`);
                
                // Get synthesize function and call immediately
                const synthFunc = pyodide.globals.get('synthesize');
                const audioProxy = synthFunc(specsProxy);  // Pass specs back to Python
                synthFunc.destroy();
                specsProxy.destroy();
                
                renderedAudio = audioProxy.toJs();  // Float32Array
                audioProxy.destroy();
                
                // Enable controls
                document.getElementById('play-btn').disabled = false;
                document.getElementById('export-btn').disabled = false;
                
                const duration = renderedAudio.length / SAMPLE_RATE;
                updateStatus(`‚úì Rendered ${duration.toFixed(2)}s audio ‚Ä¢ Click PLAY to hear`);
                btn.textContent = 'üé® Render Audio';
                btn.disabled = false;
                
            } catch (error) {
                console.error("Render error:", error);
                showError(`Render failed: ${error.message || error.toString()}`);
                updateStatus("Render failed ‚Ä¢ See error above");
                document.getElementById('render-btn').textContent = 'üé® Render Audio';
                document.getElementById('render-btn').disabled = false;
            }
        }
        
        function togglePlayback() {
            if (isPlaying) {
                stopPlayback();
                return;
            }
            
            if (!renderedAudio || renderedAudio.length === 0) {
                showError("No audio to play. Click 'Render Audio' first!");
                return;
            }
            
            playAudio();
        }
        
        function playAudio() {
            try {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                } else if (audioContext.state === 'suspended') {
                    audioContext.resume();
                }
                
                // Stop existing playback
                if (sourceNode) {
                    try { sourceNode.stop(); } catch (e) {}
                }
                
                // Create audio buffer
                audioBuffer = audioContext.createBuffer(1, renderedAudio.length, SAMPLE_RATE);
                const channelData = audioBuffer.getChannelData(0);
                for (let i = 0; i < renderedAudio.length; i++) {
                    channelData[i] = renderedAudio[i];
                }
                
                // Play
                sourceNode = audioContext.createBufferSource();
                sourceNode.buffer = audioBuffer;
                sourceNode.connect(audioContext.destination);
                sourceNode.start(0);
                
                isPlaying = true;
                document.getElementById('play-btn').textContent = '‚ñ† Stop';
                document.getElementById('play-btn').classList.add('stop');
                updateStatus("Playing audio with crossfade blending...");
                
                sourceNode.onended = () => {
                    isPlaying = false;
                    document.getElementById('play-btn').textContent = '‚ñ∂ Play';
                    document.getElementById('play-btn').classList.remove('stop');
                    updateStatus("Playback complete");
                };
                
            } catch (error) {
                console.error("Playback error:", error);
                showError(`Playback failed: ${error.message}`);
                updateStatus(`Playback error: ${error.message}`);
            }
        }
        
        function stopPlayback() {
            if (sourceNode) {
                try { sourceNode.stop(); } catch (e) {}
            }
            isPlaying = false;
            document.getElementById('play-btn').textContent = '‚ñ∂ Play';
            document.getElementById('play-btn').classList.remove('stop');
            updateStatus("Playback stopped");
        }
        
        function exportWAV() {
            if (!renderedAudio || renderedAudio.length === 0) {
                showError("No audio to export. Render audio first!");
                return;
            }
            
            try {
                const numSamples = renderedAudio.length;
                const buffer = new ArrayBuffer(44 + numSamples * 2);
                const view = new DataView(buffer);
                
                // RIFF header
                writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + numSamples * 2, true);
                writeString(view, 8, 'WAVE');
                writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, SAMPLE_RATE, true);
                view.setUint32(28, SAMPLE_RATE * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                writeString(view, 36, 'data');
                view.setUint32(40, numSamples * 2, true);
                
                // PCM data
                const int16 = new Int16Array(buffer, 44);
                for (let i = 0; i < numSamples; i++) {
                    const val = Math.max(-1, Math.min(1, renderedAudio[i]));
                    int16[i] = val < 0 ? val * 32768 : val * 32767;
                }
                
                // Download
                const blob = new Blob([buffer], { type: 'audio/wav' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `fsb4_output_${Date.now()}.wav`;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
                
                const duration = numSamples / SAMPLE_RATE;
                updateStatus(`‚úì Exported ${duration.toFixed(2)}s WAV file`);
                
            } catch (error) {
                console.error("Export error:", error);
                showError(`Export failed: ${error.message}`);
            }
        }
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
        
        // Start initialization immediately
        initPyodide();
    </script>
</body>
</html>
